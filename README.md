# Local Ollama
Simple and lightweight chat interface written in Vue for Ollama models based on the client's ollama server.

> [!WARNING]
> This project is not finished yet â€” it's just a testing demo.
> Views and components are not finalized, not optimized, and currently do not support chat history or session management.
> This is a minimal proof of concept for real-time interaction with Ollama models.

# Models not shown? (Ollama's CORS error)
Fix it using [this tutorial](https://objectgraph.com/blog/ollama-cors/)
